\lhead{\emph{Conclusion}}
\chapter{Conclusion}
% intro
In this thesis we have examined whether a mobile music player interface based on head gestures and 3D audio, could compete with a touch and vision-based music player in an "interaction in motion" scenario i.e. biking, with respect to general usability and task performance efficiency.

% related work
We started by investigating two main research areas: Mobile HCI and multimodal interaction. The mobile HCI research helped us understand the challenges that exists when people are interacting while in motion and that most mobile systems today are designed by the "stop-to-interact" model. The multimodal interaction litterature clarified the definition of modalities and their use especially in mobile systems. We delved deeper into the predefined modalities of our system; Head gestures and audio including spatial audio. We also investigated the current state on mobile audio user interfaces which included todays mobil music player interfaces and other related systems that uses auditory gesture-based interfaces.

% design, implementation
We continued by designing and implementing the Spatial Music Menu, an auditory menu interface designed for exploring and selecting music tracks using head gestures and spatial audio feedback. The system consisted of a headset (the Intelligent Headset, section \ref{sec:implementationheadset}) and an iPad running the iOS application. The design of the Spatial Music Menu was initially inspired from related systems and user feedback during the design process enabled specific features and adjustments to the system. 

% evaluation, discussion
A biking simulation system was designed to evaluate whether the Spatial Music Menu could compete with a touch and vision-based music player. During biking the participants had to perform an attention task while exploring and selecting music tracks. Results showed that participants were better at attending the surroundings with the Spatial Music Menu but they used more time navigating to the specific music tracks compaired to the touch and vision-based system. General feedback indicated that participants felt more comfortable using the Spatial Music Menu in terms of perceived workload.

In general the results showed that using systems that are based on alternative modalities like head gestures and audio can decrease the perceptual and cognitive load when interacting while in motion, compaired with systems based on touch and visual modalities. However challenges exists in making such a system as efficient as todays mobile systems. The fact that people have used touch and vision-based interfaces for a while now can have an impact i.e. it will require time for people to learn these "new" interaction modalities and a lot of systems engineering to optimize to the users behaviour.

% other findings
An interesting finding of this thesis is the strength of spatial audio. Users were able to segregate 6-8 simultanous playing sounds in our design process and in the evaluation participants could locate sounds even though they were shuffled. This indicates that the audiospace has a lot of potential when it comes to information presentation and retrieval.


\section{Future Work}
As this thesis evaluation was a controlled lab experiment it could be interesting to see how the Spatial Music Menu would perform in a real world biking scenario. This would however require some engineering as many other factors would suddenly be introduced as described in section \ref{sec:interactioninmotion}.

Although we in this thesis targeted a music player, the auditory menu could be useful in other application types as well. One could imagine music track items being replaced with other non-speech sounds for example a news site with weather news represented by weather sounds, sports news represented by sport sounds, etc. Such kind of application did not have to target interaction on the move - it could for example be suitable for visually impaired people.

Headset controllers are, as described in section \ref{sec:alternativemusicuis}, the preferred choice today when it comes to eyes-free interaction with music players. The evaluation results showed faster navigation when participants used the hand (touch) for navigating, so it could be interesting to see, if a combination of this headset controller and spatial audio output could provide the same kind of auditory menu as the Spatial Music Menu and how it would affect the usability.






% OLD

% Other use than biking scenario

% talk about how more than 3 tracks could be implemented

% solution with a headset controller + spatial audio

%Other scenarios e.g. visual impaired people, car driving...

% Thomas comments
% in general, it should contain:
% 1) reflection over the whole design process (what would you have done different, knowing what you know now (if anything)
% 2) discussion of the main findings of the evaluation (the evaluation chapter has a more detailed discussion). what does it point towards? where is the future of this kind of systems?
% 3) future work (list stuff that was found in eval which could improve future versions of the system, ideas you had yourself but discarded due to lack of resources, etc.)